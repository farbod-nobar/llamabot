{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's SimpleBot in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's say we have the text of a blog..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large Language Models (LLMs) are having a moment now!\\nWe can interact with them programmatically in ...'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./blog_text.txt\", \"r+\") as f:\n",
    "    blog_text = f.read()\n",
    "blog_text[0:100] + \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "And we'd like to create a function that takes in the text and gives us a draft LinkedIn post,\n",
    "complete with emojis,\n",
    "that is designed to entice others to read the blog post.\n",
    "LLaMaBot's `SimpleBot` lets us build that function easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "from llamabot import SimpleBot\n",
    "\n",
    "linkedin = SimpleBot(\"\"\"You are a LinkedIn post generator bot.\n",
    "A human will give you the text of a blog post that they've authored,\n",
    "and you will compose a LinkedIn post that advertises it.\n",
    "The post is intended to hook a reader into reading the blog post.\n",
    "The LinkedIn post should be written with one line per sentence.\n",
    "Each sentence should begin with an emoji appropriate to that sentence.\n",
    "The post should be written in professional English and in first-person tone for the human.\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "With `linkedin`, we can now pass in the blog text and - voila! - get back a draft LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Large Language Models (LLMs) are revolutionizing the way we write! üìù\n",
      "\n",
      "ü§ñ I explored 3 different libraries - OpenAI's API, LangChain, and LlamaIndex - to build a blog post summarization and LinkedIn post generation tool. üõ†Ô∏è\n",
      "\n",
      "üìä Each library had its pros and cons, but all provided a 100X ROI in time saved! üí∞\n",
      "\n",
      "üåê Discover my journey, comparisons, and insights in my latest blog post: [Exploring LLMs: OpenAI API, LangChain, and LlamaIndex](<blog_post_link>) üåü\n",
      "\n",
      "üîç What other high-ROI applications can you think of for LLMs? Share your thoughts in the comments! üí°\n"
     ]
    }
   ],
   "source": [
    "linkedin_post = linkedin(blog_text)\n",
    "print(linkedin_post.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now, you can edit it to your hearts content! :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
